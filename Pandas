import numpy as np
import pandas as pd

SERIES------------------------------------------------------------------------------------------------------------------
s = pd.Series(data, index = index)
 data: any data type; one-dimensional; could be {dict; ndarray; scalar value}
  if ndarray:
   len(index) = 0 or len(index) = len(data)
  if dict:
   no index passed; ordered by insertion
    if pass index, ordered by new index, and create "NaN" for those index not in dict
   if scalar value:
    must pass index; the value will be replicated;
   
  Property:
   ndarray-like:
    s[i]
     return single value without index
    s[:3]
     return slice(with index)
    s[s > condition]
     return slice under the condition
    s[[1, 2, 3]]
     return slice with index
    np.exp(s)
     calculate all the elements
   dict-like:
    s['a']
     return single value by index
    s['e'] = 1
     insert new or change
    'e' in s
     return Bool
    s.get('f', default)
     return value of 'f' or default(if not default, return None)
    s[1:] + s[:-1]
     when operation, Seires will automatically align index to value; if there is no index match, return 'NaN' for this index;   
    s.dropna()
     delete those 'NaN'
     
  Name:
   s = pd.Series(np.random.randn(5), name = 'something')
   s.name
   s1 = s.rename('anything')
    create new object
   s1.name
   
DATA FRAME-----------------------------------------------------------------------------------------------
 2-dimensional + label + columns of different types
 input: 2-d numpy.ndarray; dict of 1-d dict/ndarray/list/Series; structured ndarray; Series; Dataframe
 
 from dict of Series/Dicts:
  d = {'a':pd.Series([1, 2, 3], index = ['aa', 'bb', 'cc']), 'b':pd.Seires([2, 3, 4, 5], index = ['aa', 'bb', 'cc', 'dd'])}
  df = pd.DataFrame(d)
   if a column does not have index of other column --> NaN
  pd.DataFrame(d, index = ['dd', 'aa'], columns = ['a'])
   return Dataframe according to certain index or columns; if only pass specific set of index, then the index will override the original keys
  
 from dict of ndarrays/lists:
  d = {'a':[1, 2, 3, 4], 'b':[2, 3, 4, 5]}
  pd.DataFrame(d, index = ['aa', 'bb', 'cc', 'dd'])
  
 from structured array:
  data = np.zeros((2,), dtype = [('A', 'i4'), ('B', 'f4'), ('C', 'a10')])
  data[:] = [(1, 2., 'Hello'), (2, 3., 'Yooo')]
  pd.DataFrame(data)
  pd.DataFrame(data, index = [...], columns = ['A', 'C', 'B'])
  
 from list of dicts:
  data = [{'a':1, 'b':2}, {'a':5, 'b':6, 'c':7}]
  pd.DataFrame(data)
   columns header = keys, and if not match, return NaN
 
 from dict of tuples:
  pd.DataFrame({('a', 'b'): {('A', 'B'): 1, ('A', 'C'): 2},('a', 'a'): {('A', 'C'): 3, ('A', 'B'): 4},('a', 'c'): {('A', 'B'): 5, ('A', 'C'): 6},('b', 'a'): {('A', 'C'): 7, ('A', 'B'): 8},('b', 'b'): {('A', 'D'): 9, ('A', 'B'): 10}})
   multiple layers
   


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

###Object Creation
#Series <- List
s = pd.Series([1, 3, 5, np.nan, 6, 8])

#DataFrame <- Numpy.array
dates = pd.date_range('20130101', periods = 6)
df = pd.DataFrame(np.random.randn(6, 4), index = dates, columns = list('ABCD'))

#DataFrame <- Dict(can be converted to series-like)
df2 = pd.DataFrame({'A' : 1., 'B' : 'foo', 'E' : pd.Categorical(["test","train","test","train"])})

#Viewing Data
df.head()
df.tail(3)
df.index
df.columns
df.values # np.ndarray
df.describe() #count / mean / std / min / 25% 50% 75% / max
df.T #transpose
df.sort_index(axis = 1, ascending = False) #axis = 0 - columns / 1 - rows
df.sort_values(by = 'B')

###Selection
#single column (Series) <- DataFrame
df['A']
df[0 : 3] #slice the rows
df['20130102' : '20130104']

#Selection by Label
df.loc[dates[0]]
df.loc[:, ['A', 'B']]
df.loc['20130102':'20130104',['A','B']] # both end points are included
df.loc[dates[0], 'A'] #return scalar value
df.at[dates[0], 'A'] #same as above when getting one value

#Selection by Position
df.iloc[3] # the third row
df.iloc[3:5, 0:2] #not including the last endpoint
df.iloc[[1, 2, 4], [0, 2]] #return 3*2
df.iloc[1:3, :]
df.iloc[1, 1]
df.iat[1, 1] #same as above when getting one value

#Boolean Indexing
df[df.A > 0] #single colume value
df[df > 0] #for the whole DataFrame
df2 = df.copy()
df2['E'] = ['one', 'two', 'three', 'four', 'one', 'three']
df2[df2.E.isin(['two', 'four'])] #if df2's column has the value in {isin}

###Setting
s1 = pd.Series([1, 2, 3, 4, 5, 6], index = pd.date_range('20130101', periods = 6))
df['F'] = s1
#Setting by Label
df.at[dates[0], 'A'] = 0
#Setting by Position
df.iat[0, 1] = 0
#Assign with np.Array
df.loc[:, 'D'] = np.array([5] * len(df))
#Where Operation
df2 = df.copy()
df2[df2 > 0] = -df2 #where df2 > 0 assigned with -df2

###Missing Data ---> np.nan
#np.nan is by default not included in computations
df1 = df.reindex(index = dates[0 : 4], columns = list(df.columns) + ['E'])
df1.loc[dates[0] : dates[1], 'E'] = 1
df1.dropna(how = 'any') #drow rows that have missing data
df1.fillna(value = 5) #filling values that are missing
pd.isna(df1) #return a DataFrame contains all Booleans

###Statistics
df.mean() #by column
df.mean(1) #by rows
s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)
df.sub(s, axis = 'index') #df's value minus s value for every column

#Apply Functions
df.apply(np.cumsum)
df.apply(lambda x: x.max() - x.min())

#Histogramming
s = pd.Series(np.random.randint(0, 7, size = 10))
s.value_counts()

###String --- Series
s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CaBB', 'dog', 'cat'])
s.str.lower() #xiaoxie

###Merge
#Concatenating Pandas OBJ with concat()
df = pd.DataFrame(np.random.randn(10, 4))
pieces = [df[:3], df[3:7], df[7:]] #break into pieces by rows
pd.concat(pieces)

###Join --- SQL style Merge
left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})
right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})
pd.merge(left, right, on = 'key') #keys not change

###Append rows to DataFrame
df = pd.DataFrame(np.random.randn(8, 4), columns = ['A', 'B', 'C', 'D'])
s = df.iloc[3]
df.append(s, ignore_index = True)

###Grouping : {Splitting into Groups / Appling function to each Group / Combining Groups}
df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],
                   'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
                   'C' : np.random.randn(8),
                   'D' : np.random.randn(8)})
df.groupby('A').sum() #group to two index: foo and bar
df.groupby(['A', 'B']).sum()

###Reshaping
tuples = list(zip(*[['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]))
index = pd.MultiIndex.from_tuples(tuples, names = ['first', 'second'])
df = pd.DataFrame(np.random.randn(8, 2), index = index, columns = ['A', 'B'])
df2 = df[:4]
stacked = df2.stack() #compress the DataFrame into one column with MultiIndex
stacked.unstack() #by default the last index become column name
stacked.unstack(1) #choose the one before last one become column name
stacked.unstack(0) #choose the first one become column name

###Pivot Tables
#pd.pivot_table(df, index = [], values = [], aggfunc = [np.sum, len], columns = [], fill_value = 0, margins = True)
#index --> pick columns as index
#value --> the column you want to compute
#aggfunc ---> apply functions to values columns
#column ---> add columns when group the data
#fill_value ---> replace NaN
#margins ---> calculate the sum
#in aggfunc, we can use Dict to apply function to specific value

###Time Series
rng = pd.date_range('1/1/2012', periods = 100, freq = 'S') #second frequency
ts = pd.Series(np.random.randint(0, 500, len(rng)), index= rng)
ts.resample('5Min').sum() #make the data into data that per 5 mins

#Time Zone
rng = pd.date_range('3/6/2012 00:00', periods = 5, freq = 'D')
ts = pd.Series(np.random.randn(len(rng)), rng)
ts_utc = ts.tz_localize('UTC')
ts_utc.tz_convert('US/Eastern')
#Converting between time span representations
rng = pd.date_range('1/1/2012', periods = 5, freq = 'M')
ts = pd.Series(np.random.randn(len(rng)), index = rng)
ps = ts.to_period(freq = None, copy = True) #inferred from index if not passed
ps.to_timestamp(freq = None, how = 'start', copy = True) # how:{'s', 'e', 'start, 'end''}

prng = pd.period_range('1990Q1', '2000Q4', freq = 'Q-NOV')
ts = pd.Series(np.random.randn(len(prng)), prng)
ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9

###Categoricals
df = pd.DataFrame({"id" : [1, 2, 3, 4, 5, 6], "raw_grade" : ['a', 'b', 'b', 'a', 'a', 'e']})
print(df)
df['grade'] = df['raw_grade'].astype('category')
df['grade'].cat.categories = ['Good', 'Ok', 'Bad']

###CSV
df.to_csv('f.csv')
pd.read_csv('f.csv')

###Excel
df.to_excel('f.xlsx', sheet_name = 'Sheetttt')
pd.read_excel('f.xlsx', 'Sheet1', index_col= None, na_values = ['NA'])

 
 

